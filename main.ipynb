# -*- coding: utf-8 -*-
"""Copy of academic content creation-latex 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19y6GaJOJB4pLeCAxHT00KrE82FD-ReCj
"""

!pip install pdf2image
!sudo apt-get update
!sudo apt-get install texlive-latex-extra -y #Lighter version
#!sudo apt-get install texlive-full -y #Comprehensive version
!pip install PyPDF2
!apt-get install poppler-utils
!pip install pymupdf

import os
import re
from subprocess import run# Make sure this import is present in the same cell where you use 'run'
from pdf2image import convert_from_path
import google.generativeai as genai
import fitz  # PyMuPDF
import google.generativeai as genai
from PyPDF2 import PdfReader, PdfWriter



subject= input("enter the subject: ")
format="""\\documentclass{beamer}
          \\usetheme{Madrid}
            """
genai.configure(api_key="AIzaSyCjsqbMcPSRUrDjAyiP4A8UfKiI75FizG0")

model = genai.GenerativeModel('gemini-1.5-flash')
response = model.generate_content(" generate code with 10 slides of the "+format+"about the"+subject+"with out comments and exclude ```tex ``` ,end with thankyou slide" )
with open("response.txt", "w") as file:
    file.write(response.text)
print(response.text)



# Write the LaTeX code to a .tex file
with open('presentation.tex', 'w') as f:
    f.write(response.text)

# Compile the LaTeX code into a PDF
run(['pdflatex', 'presentation.tex'])

# Clean up auxiliary files generated by pdflatex
auxiliary_files = ['presentation.aux', 'presentation.log', 'presentation.nav', 'presentation.snm', 'presentation.toc']
for filename in auxiliary_files:
    if os.path.exists(filename):
        os.remove(filename)

from google.colab import files
files.download('presentation.pdf')

def remove_footer(input_pdf, output_pdf, footer_height):
    # Read the original PDF
    reader = PdfReader(input_pdf)
    writer = PdfWriter()

    for page in reader.pages:
        # Get the original page dimensions
        original_width = page.mediabox.width
        original_height = page.mediabox.height

        # Adjust the page's lower boundary to remove the footer
        page.mediabox.lower_left = (0, footer_height)

        # Add the modified page to the writer
        writer.add_page(page)

    # Write the output PDF with the footer removed
    with open(output_pdf, 'wb') as out_file:
        writer.write(out_file)

# Example usage
input_pdf = 'presentation.pdf'           # Input PDF file with footer
output_pdf = 'output_no_footer.pdf'  # Output PDF file without footer
footer_height = 50  # Height of the footer to remove (adjust as needed)

remove_footer(input_pdf, output_pdf, footer_height)

# Convert PDF to images
images = convert_from_path('presentation.pdf')
extracted_texts = []
for i, image in enumerate(images):
    image.save(f'slide_{i+1}.png')

def pdf_to_text_list(pdf_path):
    # Open the PDF file
    document = fitz.open(pdf_path)

    # Initialize an empty list to store text from each page
    text_list = []

    # Iterate over each page
    for page_num in range(len(document)):
        # Get the page
        page = document.load_page(page_num)

        # Extract text from the page
        text = page.get_text()

        # Append the text to the list
        text_list.append(text)

    # Close the document
    document.close()

    return text_list

# Example usage
pdf_path = 'output_no_footer.pdf'  # Replace with your PDF file path
text_list = pdf_to_text_list(pdf_path)

# Print out the text from each page
for i, page_text in enumerate(text_list):
    print(f"Page {i + 1}:")
    print(page_text)
    print("\n--- End of Page ---\n")


import random

# Configure the API
genai.configure(api_key="AIzaSyCjsqbMcPSRUrDjAyiP4A8UfKiI75FizG0")

# Initialize the model
model = genai.GenerativeModel('gemini-1.5-flash')

# List to store the responses
responses = []

# List of salutations
salutations = ["Moving on,", "Next up,", "Let's continue,"]

# Generate the first slide's response separately
first_slide_response = model.generate_content(text_list[0] + " just introduce about the subject ")
responses.append(first_slide_response.text)

# Process the text inputs except the last one
for txt in text_list[1:-1]:
    # Select a random salutation
    salutation = random.choice(salutations)
    # Generate content with the salutation
    response = model.generate_content( txt + " explain in short paragraph  starts with a " + salutation )
    responses.append(response.text)

# Generate the last slide's response separately
last_slide_text = text_list[-1].strip().lower()

if last_slide_text.startswith("thank you") or last_slide_text.startswith("questions"):
    last_slide_response = model.generate_content(text_list[-1] + " print this word as it is ")
else:
    last_slide_response = model.generate_content("Finally, " + text_list[-1] + " explain in short paragraph ")

responses.append(last_slide_response.text)

# Save responses to a file
with open("responses.txt", "w") as file:
    for response_text in responses:
        file.write(response_text + "\n")

# Print all responses
for response_text in responses:
    print(response_text)

import re

# Define a function to remove unwanted symbols except for "." and ","
def clean_word(word):
    # Remove all symbols except for "." and "," using regular expressions
    return re.sub(r'[^\w\s\.,:]', '', word)

# Apply the function to each word in the list
cleaned_words = [clean_word(word) for word in responses]

print("Cleaned words:", cleaned_words)


!pip install --upgrade google-cloud-texttospeech
from google.colab import files
files.upload()  # Upload the service account JSON key file

# Set the environment variable to point to your key file
import os
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "projectrit-bb9d783f6699.json"

from google.cloud import texttospeech
from pydub import AudioSegment

# Initialize the Google Cloud Text-to-Speech client
client = texttospeech.TextToSpeechClient()

# Iterate through each text in cleaned_words
for i, text in enumerate(cleaned_words):
    # Set the text input to be synthesized
    synthesis_input = texttospeech.SynthesisInput(text=text)

    # Build the voice request, select the language code and the name of the voice
    voice = texttospeech.VoiceSelectionParams(
        language_code="en-US",
        name="en-US-Wavenet-D",  # Change this to the desired voice
        ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL
    )

    # Select the type of audio file you want returned
    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3
    )

    # Perform the text-to-speech request
    response = client.synthesize_speech(
        input=synthesis_input, voice=voice, audio_config=audio_config
    )

    # Save the synthesized audio to a file
    audio_filename = f'slide2_{i+1}.mp3'
    with open(audio_filename, "wb") as out:
        out.write(response.audio_content)
        print(f"Audio content written to file '{audio_filename}'")

    # Optional: Load the audio into pydub for further processing if needed
    audio = AudioSegment.from_mp3(audio_filename)

    # Additional processing with pydub can be done here, e.g., adjusting volume, concatenating files, etc.

!pip install pydub
!apt-get install ffmpeg

from pydub import AudioSegment

def reencode_audio(input_file, output_file):
    audio = AudioSegment.from_file(input_file)
    audio.export(output_file, format="mp3")

# Re-encode each audio file
for i in range(len(text_list)):
    reencode_audio(f'slide2_{i+1}.mp3', f'slide2_{i+1}_reencoded.mp3')

!pip install --upgrade moviepy

from moviepy.editor import ImageClip, AudioFileClip, concatenate_videoclips

# List to store video clips
clips = []

# Create video clips from images and a single audio clip
for i in range(len(images)):
    img_clip = ImageClip(f'slide_{i+1}.png')
    audio_clip = AudioFileClip(f'slide2_{i+1}_reencoded.mp3')
    img_clip = img_clip.set_duration(audio_clip.duration)  # Set image duration to match audio duration
    video_clip = img_clip.set_audio(audio_clip)
    clips.append(video_clip)

# Concatenate all video clips
final_video = concatenate_videoclips(clips, method="compose")
final_video.write_videofile("presentation.mp4", fps=24)

from google.colab import files
files.download('presentation.mp4')
